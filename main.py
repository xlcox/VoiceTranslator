import sounddevice as sd
import numpy as np
import edge_tts
import whisper
from deep_translator import GoogleTranslator
import keyboard
import asyncio
import soundfile as sf
import os

# ---------------- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ----------------
FS = 16000
HOTKEY = 'page up'
MIN_AUDIO_SEC = 0.8
TTS_FILE = "tts.wav"

# ---------------- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ----------------
model = whisper.load_model("small")
translator = GoogleTranslator(source='ru', target='zh-CN')

audio_buffer = []
recording = False


# ---------------- –ê—É–¥–∏–æ callback ----------------
def audio_callback(indata, frames, time_info, status):
    if recording:
        audio_buffer.append(indata.copy())


# ---------------- Whisper ----------------
def speech_to_text(audio):
    if np.max(np.abs(audio)) < 0.01:
        print("‚ö†Ô∏è –°–ª–∏—à–∫–æ–º —Ç–∏—Ö–∏–π –∑–≤—É–∫")
        return ""
    result = model.transcribe(audio, language='ru')
    return result["text"].strip()


# ---------------- TTS ----------------
async def speak(text, filename=TTS_FILE):
    communicate = edge_tts.Communicate(
        text,
        voice="zh-CN-YunxiNeural",  # –º—É–∂—Å–∫–æ–π –≥–æ–ª–æ—Å
        volume="+30%",               # –≥—Ä–æ–º–∫–æ—Å—Ç—å
        rate="-20%"                  # —É–º–µ–Ω—å—à–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ –Ω–∞ 20%
    )
    await communicate.save(filename)
    return os.path.exists(filename) and os.path.getsize(filename) > 0


def play_audio(filename, gain=1.5):
    data, sr = sf.read(filename, dtype='float32')

    # –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —É—Å–∏–ª–µ–Ω–∏–µ
    data *= gain
    data = np.clip(data, -1.0, 1.0)

    sd.play(data, sr)
    sd.wait()


# ---------------- –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª ----------------
async def main():
    global recording, audio_buffer

    print(f"üé§ –£–¥–µ—Ä–∂–∏–≤–∞–π—Ç–µ '{HOTKEY}' –¥–ª—è –∑–∞–ø–∏—Å–∏")

    with sd.InputStream(
            samplerate=FS,
            channels=1,
            dtype='float32',
            callback=audio_callback
    ):
        while True:
            if keyboard.is_pressed(HOTKEY):
                if not recording:
                    audio_buffer = []
                    recording = True
                    print("‚ñ∂Ô∏è –ó–∞–ø–∏—Å—å...")
            else:
                if recording:
                    recording = False
                    print("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞")

                    if not audio_buffer:
                        continue

                    audio = np.concatenate(audio_buffer, axis=0).flatten()
                    duration = len(audio) / FS
                    print(f"‚è± –î–ª–∏–Ω–∞: {duration:.2f} —Å–µ–∫")

                    if duration < MIN_AUDIO_SEC:
                        print("‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ")
                        continue

                    text = speech_to_text(audio)
                    print("üìù RU:", text)

                    if not text:
                        continue

                    translated = translator.translate(text)
                    print("üåè ZH:", translated)

                    if await speak(translated):
                        play_audio(TTS_FILE, gain=1.5)

            await asyncio.sleep(0.05)


# ---------------- –ó–∞–ø—É—Å–∫ ----------------
asyncio.run(main())
